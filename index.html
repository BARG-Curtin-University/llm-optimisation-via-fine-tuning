<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Borck">
<meta name="dcterms.date" content="2024-05-22">
<meta name="keywords" content="Fine-tuning, Large language models (LLMs), Optimisation, Natural Language Processing (NLP), Best practices">

<title>Optimising Large Language Models Through Fine-Tuning: Methods and Best Practices</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>


<meta name="citation_title" content="Optimising Large Language Models Through Fine-Tuning: Methods and Best Practices">
<meta name="citation_abstract" content="&amp;amp;quot;Large language models (LLMs) have revolutionised natural language processing (NLP) by providing advanced capabilities for tasks such as text generation, translation, summarisation, and question answering. Despite their power, LLMs often require fine-tuning to address specific tasks or domains effectively. This paper provides a comprehensive overview of fine-tuning LLMs, discussing various approaches, methods, and best practices. We explore how fine-tuning can enhance model performance, reduce training costs, and yield more accurate, context-specific results.&quot;
">
<meta name="citation_keywords" content="Fine-tuning,Large language models (LLMs),Optimisation,Natural Language Processing (NLP),Best practices">
<meta name="citation_author" content="Michael Borck">
<meta name="citation_publication_date" content="2024-05-22">
<meta name="citation_cover_date" content="2024-05-22">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-05-22">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="BARG Curtin University">
<meta name="citation_reference" content="citation_title=Literate programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Optimising Large Language Models Through Fine-Tuning: Methods and Best Practices</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Author</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Michael Borck <a href="mailto:michael.borck@curtin.edu.au" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-0950-6396" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Business Information Systems, Curtin University, Perth Australia
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">May 22, 2024</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></p></div><div class="quarto-title-meta-contents"><p><a href="index-meca.zip" data-meca-link="true"><i class="bi bi-archive"></i>MECA Bundle</a></p></div></div></div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>“Large language models (LLMs) have revolutionised natural language processing (NLP) by providing advanced capabilities for tasks such as text generation, translation, summarisation, and question answering. Despite their power, LLMs often require fine-tuning to address specific tasks or domains effectively. This paper provides a comprehensive overview of fine-tuning LLMs, discussing various approaches, methods, and best practices. We explore how fine-tuning can enhance model performance, reduce training costs, and yield more accurate, context-specific results.”</p>
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>Fine-tuning, Large language models (LLMs), Optimisation, Natural Language Processing (NLP), Best practices</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#what-is-fine-tuning-and-why-is-it-necessary" id="toc-what-is-fine-tuning-and-why-is-it-necessary" class="nav-link" data-scroll-target="#what-is-fine-tuning-and-why-is-it-necessary"><span class="header-section-number">2</span> What is Fine-Tuning and Why is it Necessary?</a>
  <ul class="collapse">
  <li><a href="#customisation" id="toc-customisation" class="nav-link" data-scroll-target="#customisation"><span class="header-section-number">2.1</span> Customisation</a></li>
  <li><a href="#data-compliance" id="toc-data-compliance" class="nav-link" data-scroll-target="#data-compliance"><span class="header-section-number">2.2</span> Data Compliance</a></li>
  <li><a href="#limited-labeled-data" id="toc-limited-labeled-data" class="nav-link" data-scroll-target="#limited-labeled-data"><span class="header-section-number">2.3</span> Limited Labeled Data</a></li>
  </ul></li>
  <li><a href="#primary-fine-tuning-approaches" id="toc-primary-fine-tuning-approaches" class="nav-link" data-scroll-target="#primary-fine-tuning-approaches"><span class="header-section-number">3</span> Primary Fine-Tuning Approaches</a>
  <ul class="collapse">
  <li><a href="#feature-extraction-repurposing" id="toc-feature-extraction-repurposing" class="nav-link" data-scroll-target="#feature-extraction-repurposing"><span class="header-section-number">3.1</span> Feature Extraction (Repurposing)</a></li>
  <li><a href="#full-fine-tuning" id="toc-full-fine-tuning" class="nav-link" data-scroll-target="#full-fine-tuning"><span class="header-section-number">3.2</span> Full Fine-Tuning</a></li>
  </ul></li>
  <li><a href="#prominent-fine-tuning-methods" id="toc-prominent-fine-tuning-methods" class="nav-link" data-scroll-target="#prominent-fine-tuning-methods"><span class="header-section-number">4</span> Prominent Fine-Tuning Methods</a>
  <ul class="collapse">
  <li><a href="#supervised-fine-tuning" id="toc-supervised-fine-tuning" class="nav-link" data-scroll-target="#supervised-fine-tuning"><span class="header-section-number">4.1</span> Supervised Fine-Tuning</a></li>
  <li><a href="#reinforcement-learning-from-human-feedback-rlhf" id="toc-reinforcement-learning-from-human-feedback-rlhf" class="nav-link" data-scroll-target="#reinforcement-learning-from-human-feedback-rlhf"><span class="header-section-number">4.2</span> Reinforcement Learning from Human Feedback (RLHF)</a></li>
  </ul></li>
  <li><a href="#fine-tuning-process-and-best-practices" id="toc-fine-tuning-process-and-best-practices" class="nav-link" data-scroll-target="#fine-tuning-process-and-best-practices"><span class="header-section-number">5</span> Fine-Tuning Process and Best Practices</a></li>
  <li><a href="#applications-of-fine-tuning" id="toc-applications-of-fine-tuning" class="nav-link" data-scroll-target="#applications-of-fine-tuning"><span class="header-section-number">6</span> Applications of Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#sentiment-analysis" id="toc-sentiment-analysis" class="nav-link" data-scroll-target="#sentiment-analysis"><span class="header-section-number">6.1</span> Sentiment Analysis</a></li>
  <li><a href="#chatbots" id="toc-chatbots" class="nav-link" data-scroll-target="#chatbots"><span class="header-section-number">6.2</span> Chatbots</a></li>
  <li><a href="#summarisation" id="toc-summarisation" class="nav-link" data-scroll-target="#summarisation"><span class="header-section-number">6.3</span> Summarisation</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">7</span> Conclusion</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Large language models (LLMs), pre-trained on extensive datasets, have become indispensable tools in NLP, enabling sophisticated solutions across diverse applications. However, their general-purpose nature often necessitates fine-tuning to meet specific task or domain requirements. Fine-tuning involves adapting pre-trained models on smaller, task-specific datasets, thereby improving their performance in targeted applications while preserving their broad language understanding. For instance, a Google study demonstrated a 10% accuracy improvement in sentiment analysis through fine-tuning.<sup>1</sup> This paper aims to elucidate the importance of fine-tuning, outline various techniques, and present best practices for effective implementation.</p>
</section>
<section id="what-is-fine-tuning-and-why-is-it-necessary" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="what-is-fine-tuning-and-why-is-it-necessary"><span class="header-section-number">2</span> What is Fine-Tuning and Why is it Necessary?</h2>
<p>Fine-tuning entails adjusting the parameters of a pre-trained LLM to align with a particular task or domain. While pre-trained models like GPT possess extensive language knowledge, they often lack domain-specific expertise. Fine-tuning bridges this gap, enabling models to learn from specialised data and thus enhancing their accuracy and relevance.</p>
<section id="customisation" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="customisation"><span class="header-section-number">2.1</span> Customisation</h3>
<p>Domains such as legal, medical, or business analytics have unique language patterns and terminologies. Fine-tuning allows LLMs to grasp these specificities, producing content that is accurate and contextually relevant to the domain.</p>
</section>
<section id="data-compliance" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="data-compliance"><span class="header-section-number">2.2</span> Data Compliance</h3>
<p>Industries like healthcare, finance, and law require strict adherence to data compliance standards. Fine-tuning LLMs on proprietary or regulated datasets ensures compliance and enhances data ecurity and privacy.</p>
</section>
<section id="limited-labeled-data" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="limited-labeled-data"><span class="header-section-number">2.3</span> Limited Labeled Data</h3>
<p>In scenarios where labeled data is scarce, fine-tuning maximises the utility of available data, improving model accuracy and relevance without extensive data requirements.</p>
</section>
</section>
<section id="primary-fine-tuning-approaches" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="primary-fine-tuning-approaches"><span class="header-section-number">3</span> Primary Fine-Tuning Approaches</h2>
<p>Fine-tuning strategies can vary based on the task’s specificity. The two primary approaches are:</p>
<section id="feature-extraction-repurposing" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="feature-extraction-repurposing"><span class="header-section-number">3.1</span> Feature Extraction (Repurposing)</h3>
<p>This approach treats the pre-trained LLM as a fixed feature extractor, training only the final layers on task-specific data. It leverages the model’s pre-existing language features, offering a cost-effective and efficient fine-tuning method.</p>
</section>
<section id="full-fine-tuning" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="full-fine-tuning"><span class="header-section-number">3.2</span> Full Fine-Tuning</h3>
<p>Here, the entire model is retrained on task-specific data. This method is suitable for significantly different datasets from the pre-training corpus, requiring more computational resources but potentially yielding superior adaptation and performance.</p>
</section>
</section>
<section id="prominent-fine-tuning-methods" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="prominent-fine-tuning-methods"><span class="header-section-number">4</span> Prominent Fine-Tuning Methods</h2>
<section id="supervised-fine-tuning" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="supervised-fine-tuning"><span class="header-section-number">4.1</span> Supervised Fine-Tuning</h3>
<p>In supervised fine-tuning, models are trained on labeled datasets to predict specific outputs. Techniques include:</p>
<ul>
<li><strong>Basic Hyperparameter Tuning:</strong> Manually adjusting hyperparameters like learning rate and batch size.</li>
<li><strong>Transfer Learning:</strong> Adapting a pre-trained model to new tasks with limited data.</li>
<li><strong>Multi-Task Learning:</strong> Training on multiple related tasks simultaneously to improve generalisation.</li>
<li><strong>Few-Shot Learning:</strong> Adapting the model with minimal task-specific data.</li>
<li><strong>Task-Specific Fine-Tuning:</strong> Tailoring the model to excel in a single, well-defined task.</li>
</ul>
</section>
<section id="reinforcement-learning-from-human-feedback-rlhf" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="reinforcement-learning-from-human-feedback-rlhf"><span class="header-section-number">4.2</span> Reinforcement Learning from Human Feedback (RLHF)</h3>
<p>RLHF involves training models through human interactions, incorporating feedback to refine model outputs. Techniques include:</p>
<ul>
<li><strong>Reward Modeling:</strong> Using human-provided rankings to guide model adjustments.</li>
<li><strong>Proximal Policy Optimisation (PPO):</strong> Iteratively updating policies to maximise expected rewards.</li>
<li><strong>Comparative Ranking:</strong> Learning from relative rankings of multiple outputs.</li>
<li><strong>Preference Learning:</strong> Training based on human preferences between outputs.</li>
</ul>
</section>
</section>
<section id="fine-tuning-process-and-best-practices" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="fine-tuning-process-and-best-practices"><span class="header-section-number">5</span> Fine-Tuning Process and Best Practices</h2>
<ol type="1">
<li><strong>Data Preparation:</strong> Curate and preprocess datasets to ensure relevance and quality, employing data augmentation techniques as needed.</li>
<li><strong>Model Selection:</strong> Choose a pre-trained model that aligns with the target task, considering architecture, specifications, and performance.</li>
<li><strong>Parameter Configuration:</strong> Optimise learning rates, batch sizes, and other parameters to balance learning efficiency and overfitting risks.</li>
<li><strong>Validation:</strong> Evaluate model performance using metrics like accuracy and loss, refining parameters and architecture based on results.</li>
<li><strong>Iteration:</strong> Iteratively adjust fine-tuning strategies to enhance model capabilities until desired performance levels are achieved.</li>
<li><strong>Deployment:</strong> Integrate the fine-tuned model into practical applications, considering scalability, performance, and security.</li>
</ol>
</section>
<section id="applications-of-fine-tuning" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="applications-of-fine-tuning"><span class="header-section-number">6</span> Applications of Fine-Tuning</h2>
<section id="sentiment-analysis" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="sentiment-analysis"><span class="header-section-number">6.1</span> Sentiment Analysis</h3>
<p>Fine-tuned models can analyse sentiment in specific datasets, providing insights from customer feedback and social media.</p>
</section>
<section id="chatbots" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="chatbots"><span class="header-section-number">6.2</span> Chatbots</h3>
<p>Fine-tuning enables chatbots to generate more relevant and engaging conversations, enhancing customer interactions in various sectors.</p>
</section>
<section id="summarisation" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="summarisation"><span class="header-section-number">6.3</span> Summarisation</h3>
<p>Fine-tuned models can efficiently summarise lengthy documents, aiding in information retrieval and knowledge management.</p>
</section>
</section>
<section id="conclusion" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">7</span> Conclusion</h2>
<p>Fine-tuning LLMs is a vital process for adapting general-purpose models to specific tasks or domains. By employing the methods and best practices discussed, organisations can significantly enhance model performance and achieve contextually accurate results. Turing’s expertise in fine-tuning and training LLMs offers tailored solutions for seamless business integration, enabling advanced LLM-powered applications at scale.</p>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{borck2024,
  author = {Borck, Michael},
  title = {Optimising {Large} {Language} {Models} {Through}
    {Fine-Tuning:} {Methods} and {Best} {Practices}},
  date = {2024-05-22},
  langid = {en},
  abstract = {“Large language models (LLMs) have revolutionised natural
    language processing (NLP) by providing advanced capabilities for
    tasks such as text generation, translation, summarisation, and
    question answering. Despite their power, LLMs often require
    fine-tuning to address specific tasks or domains effectively. This
    paper provides a comprehensive overview of fine-tuning LLMs,
    discussing various approaches, methods, and best practices. We
    explore how fine-tuning can enhance model performance, reduce
    training costs, and yield more accurate, context-specific results.”}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-borck2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Borck, Michael. 2024. <span>“Optimising Large Language Models Through
Fine-Tuning: Methods and Best Practices.”</span> BARG Curtin University.
May 22, 2024.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>